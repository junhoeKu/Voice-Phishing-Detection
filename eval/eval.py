"""
ëª¨ë¸ í‰ê°€ ëª¨ë“ˆ

í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ í‰ê°€í•˜ê³  ì„±ëŠ¥ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
    python eval/eval.py --test_data dataset/test.csv --adapter_path model/my_adapter
"""

import os
import torch
import random
import numpy as np
import pandas as pd
import argparse
from pathlib import Path
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from datasets import load_dataset


def set_seed(seed: int = 42):
    """
    ë‚œìˆ˜ ì‹œë“œ ê³ ì •
    
    Args:
        seed: ì‹œë“œ ê°’ (ê¸°ë³¸ê°’: 42)
    """
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)


def setup_environment(cache_dir: str = "cache", hf_cache_dir: str = None):
    """
    í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    
    Args:
        cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        hf_cache_dir: Hugging Face ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ, Noneì´ë©´ cache_dir ì‚¬ìš©)
    """
    base_path = Path(__file__).parent.parent
    cache_path = base_path / cache_dir
    cache_path.mkdir(parents=True, exist_ok=True)
    
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    os.environ["TRANSFORMERS_CACHE"] = str(cache_path)
    os.environ["TRITON_CACHE_DIR"] = str(cache_path / "triton")
    
    if hf_cache_dir:
        hf_cache_path = base_path / hf_cache_dir
        hf_cache_path.mkdir(parents=True, exist_ok=True)
        os.environ["HUGGINGFACE_HUB_CACHE"] = str(hf_cache_path)
    else:
        os.environ["HUGGINGFACE_HUB_CACHE"] = str(cache_path / "hf_cache")


def preprocess_input(text: str) -> str:
    """
    ì…ë ¥ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    
    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    return " ".join(text.strip().split())


def load_model_and_tokenizer(
    base_model_path: str,
    adapter_path: str,
    tokenizer_path: str = None,
    cache_dir: str = "cache",
    device: str = None,
    merge_adapter: bool = True
):
    """
    ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
    
    Args:
        base_model_path: ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ
        adapter_path: ì–´ëŒ‘í„° ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        tokenizer_path: í† í¬ë‚˜ì´ì € ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ, Noneì´ë©´ base_model_path ì‚¬ìš©)
        cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        device: ë””ë°”ì´ìŠ¤ (Noneì´ë©´ ìë™ ì„ íƒ)
        merge_adapter: ì–´ëŒ‘í„° ë³‘í•© ì—¬ë¶€
        
    Returns:
        (model, tokenizer) íŠœí”Œ
    """
    base_path = Path(__file__).parent.parent
    adapter_full_path = base_path / adapter_path
    cache_full_path = base_path / cache_dir
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # í† í¬ë‚˜ì´ì € ê²½ë¡œ ì„¤ì •
    if tokenizer_path is None:
        tokenizer_path = base_model_path
    else:
        tokenizer_full_path = base_path / tokenizer_path
        if tokenizer_full_path.exists():
            tokenizer_path = str(tokenizer_full_path)
    
    print(f"ğŸ“¥ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")
    tokenizer = AutoTokenizer.from_pretrained(
        tokenizer_path,
        cache_dir=str(cache_full_path)
    )
    tokenizer.pad_token = tokenizer.eos_token
    print("âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")
    
    # ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ“¥ ê¸°ë³¸ ëª¨ë¸ ë¡œë”© ì¤‘... ({base_model_path})")
    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.bfloat16
    
    base_model = AutoModelForSequenceClassification.from_pretrained(
        base_model_path,
        num_labels=2,
        torch_dtype=torch_dtype,
        cache_dir=str(cache_full_path),
        low_cpu_mem_usage=True,
        device_map=device if device.startswith("cuda") else None
    )
    
    # PEFT ì–´ëŒ‘í„° ë¡œë“œ
    if not adapter_full_path.exists():
        raise FileNotFoundError(f"ì–´ëŒ‘í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {adapter_full_path}")
    
    print(f"ğŸ“¥ ì–´ëŒ‘í„° ë¡œë”© ì¤‘... ({adapter_path})")
    model = PeftModel.from_pretrained(base_model, str(adapter_full_path))
    
    # ì–´ëŒ‘í„° ë³‘í•©
    if merge_adapter:
        print("ğŸ”— ì–´ëŒ‘í„° ë³‘í•© ì¤‘...")
        model = model.merge_and_unload()
    
    model.eval()
    for p in model.parameters():
        p.requires_grad = False
    
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    return model, tokenizer


def evaluate_model(
    model,
    tokenizer,
    test_data_path: str,
    max_length: int = 1024,
    label_map: dict = None
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    ëª¨ë¸ í‰ê°€ ìˆ˜í–‰
    
    Args:
        model: í‰ê°€í•  ëª¨ë¸
        tokenizer: í† í¬ë‚˜ì´ì €
        test_data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        max_length: ìµœëŒ€ ì…ë ¥ ê¸¸ì´ (ê¸°ë³¸ê°’: 1024)
        label_map: ë¼ë²¨ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ (ê¸°ë³¸ê°’: {0: "ì •ìƒ", 1: "ë³´ì´ìŠ¤í”¼ì‹±"})
        
    Returns:
        (ì˜ˆì¸¡_ê²°ê³¼_DataFrame, í‰ê°€_ì§€í‘œ_DataFrame) íŠœí”Œ
    """
    base_path = Path(__file__).parent.parent
    test_data_full_path = base_path / test_data_path
    
    if not test_data_full_path.exists():
        raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_data_full_path}")
    
    # ë¼ë²¨ ë§¤í•‘ ì„¤ì •
    if label_map is None:
        label_map = {0: "ì •ìƒ", 1: "ë³´ì´ìŠ¤í”¼ì‹±"}
    
    inv_label_map = {v: k for k, v in label_map.items()}
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ
    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘... ({test_data_path})")
    test_dataset = load_dataset("csv", data_files=str(test_data_full_path))["train"]
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}ê°œ")
    
    records = []
    y_true = []
    y_pred = []
    
    # í‰ê°€ ìˆ˜í–‰
    print("ğŸ§ª í‰ê°€ ìˆ˜í–‰ ì¤‘...")
    for sample in tqdm(test_dataset, desc="í‰ê°€ ì§„í–‰"):
        input_text = sample["text"]
        
        # ë¼ë²¨ ì»¬ëŸ¼ëª… í™•ì¸ (Label ë˜ëŠ” label)
        label_key = "Label" if "Label" in sample else "label"
        target_label_idx = sample[label_key]
        target_label = label_map[target_label_idx]
        
        # ì „ì²˜ë¦¬ ë° í† í¬ë‚˜ì´ì§•
        preprocessed_text = preprocess_input(input_text)
        inputs = tokenizer(
            preprocessed_text,
            return_tensors="pt",
            padding="max_length",
            truncation=True,
            max_length=max_length,
            return_token_type_ids=False
        )
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            logits = model(**inputs).logits
            predicted_label_idx = torch.argmax(logits, dim=-1).item()
        
        pred_text = label_map[predicted_label_idx]
        is_correct = (pred_text == target_label)
        
        y_true.append(target_label_idx)
        y_pred.append(predicted_label_idx)
        
        records.append({
            "Input": input_text,
            "Prediction": pred_text,
            "Label": target_label,
            "Correct": int(is_correct)
        })
    
    # ì§€í‘œ ê³„ì‚°
    print("ğŸ“ í‰ê°€ ì§€í‘œ ê³„ì‚° ì¤‘...")
    acc = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    
    # ê²°ê³¼ DataFrame ìƒì„±
    results_df = pd.DataFrame(records)
    scores_df = pd.DataFrame([{
        "Accuracy": acc,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1
    }])
    
    return results_df, scores_df


def save_results(
    results_df: pd.DataFrame,
    scores_df: pd.DataFrame,
    results_path: str,
    scores_path: str
):
    """
    í‰ê°€ ê²°ê³¼ ì €ì¥
    
    Args:
        results_df: ì˜ˆì¸¡ ê²°ê³¼ DataFrame
        scores_df: í‰ê°€ ì§€í‘œ DataFrame
        results_path: ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        scores_path: í‰ê°€ ì§€í‘œ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
    """
    base_path = Path(__file__).parent.parent
    results_full_path = base_path / results_path
    scores_full_path = base_path / scores_path
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    results_full_path.parent.mkdir(parents=True, exist_ok=True)
    scores_full_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ì €ì¥
    results_df.to_csv(results_full_path, index=False, encoding="utf-8-sig")
    scores_df.to_csv(scores_full_path, index=False, encoding="utf-8-sig")
    
    print(f"ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {results_full_path}")
    print(f"ğŸ’¾ í‰ê°€ ì§€í‘œ ì €ì¥: {scores_full_path}")


def evaluate_and_save(
    base_model_path: str,
    adapter_path: str,
    test_data_path: str,
    tokenizer_path: str = None,
    results_path: str = "results/eval_results.csv",
    scores_path: str = "results/eval_metrics.csv",
    cache_dir: str = "cache",
    device: str = None,
    merge_adapter: bool = True,
    max_length: int = 1024
):
    """
    ëª¨ë¸ í‰ê°€ ë° ê²°ê³¼ ì €ì¥
    
    Args:
        base_model_path: ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ
        adapter_path: ì–´ëŒ‘í„° ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        test_data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        tokenizer_path: í† í¬ë‚˜ì´ì € ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ, Noneì´ë©´ base_model_path ì‚¬ìš©)
        results_path: ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        scores_path: í‰ê°€ ì§€í‘œ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        device: ë””ë°”ì´ìŠ¤ (Noneì´ë©´ ìë™ ì„ íƒ)
        merge_adapter: ì–´ëŒ‘í„° ë³‘í•© ì—¬ë¶€
        max_length: ìµœëŒ€ ì…ë ¥ ê¸¸ì´
    """
    # í™˜ê²½ ì„¤ì •
    setup_environment(cache_dir)
    set_seed(42)
    
    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
    model, tokenizer = load_model_and_tokenizer(
        base_model_path=base_model_path,
        adapter_path=adapter_path,
        tokenizer_path=tokenizer_path,
        cache_dir=cache_dir,
        device=device,
        merge_adapter=merge_adapter
    )
    
    # í‰ê°€ ìˆ˜í–‰
    results_df, scores_df = evaluate_model(
        model=model,
        tokenizer=tokenizer,
        test_data_path=test_data_path,
        max_length=max_length
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nâœ… í‰ê°€ ì§€í‘œ:")
    print(scores_df.to_string(index=False, float_format="%.4f"))
    
    # ê²°ê³¼ ì €ì¥
    save_results(results_df, scores_df, results_path, scores_path)
    
    print("\nâœ… í‰ê°€ ì™„ë£Œ!")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ëª¨ë¸ í‰ê°€")
    parser.add_argument("--base_model", type=str, default="maywell/Synatra-42dot-1.3B", help="ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--adapter_path", type=str, required=True, help="ì–´ëŒ‘í„° ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)")
    parser.add_argument("--test_data", type=str, required=True, help="í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)")
    parser.add_argument("--tokenizer_path", type=str, default=None, help="í† í¬ë‚˜ì´ì € ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ, Noneì´ë©´ base_model ì‚¬ìš©)")
    parser.add_argument("--results_path", type=str, default="results/eval_results.csv", help="ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)")
    parser.add_argument("--scores_path", type=str, default="results/eval_metrics.csv", help="í‰ê°€ ì§€í‘œ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)")
    parser.add_argument("--cache_dir", type=str, default="cache", help="ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)")
    parser.add_argument("--device", type=str, default=None, help="ë””ë°”ì´ìŠ¤ (cuda/cpu, Noneì´ë©´ ìë™ ì„ íƒ)")
    parser.add_argument("--no_merge", action="store_true", help="ì–´ëŒ‘í„° ë³‘í•©í•˜ì§€ ì•Šê¸°")
    parser.add_argument("--max_length", type=int, default=1024, help="ìµœëŒ€ ì…ë ¥ ê¸¸ì´")
    args = parser.parse_args()
    
    evaluate_and_save(
        base_model_path=args.base_model, adapter_path=args.adapter_path, test_data_path=args.test_data,
        tokenizer_path=args.tokenizer_path, results_path=args.results_path, scores_path=args.scores_path,
        cache_dir=args.cache_dir, device=args.device, merge_adapter=not args.no_merge, max_length=args.max_length
    )


if __name__ == "__main__":
    main()

