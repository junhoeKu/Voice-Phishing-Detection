"""
Random Forest ëª¨ë¸ í•™ìŠµ ë° í‰ê°€

TF-IDF ë²¡í„°í™”ì™€ Random Forestë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ì´ìŠ¤í”¼ì‹± íƒì§€ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
5íšŒ ì‹¤í–‰ì˜ í‰ê·  ì„±ëŠ¥ì„ ê³„ì‚°í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
    python train/rf_train.py --data dataset/total_dataset.csv
"""

import os
import random
import argparse
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score, recall_score, precision_score, accuracy_score
from sklearn.ensemble import RandomForestClassifier
import wandb


def set_seed(seed: int = 42):
    """ë‚œìˆ˜ ì‹œë“œ ê³ ì •"""
    random.seed(seed)
    np.random.seed(seed)


def load_data(data_path: str, text_column: str = "text", label_column: str = "label"):
    """
    ë°ì´í„° ë¡œë“œ
    
    Args:
        data_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        text_column: í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
        label_column: ë¼ë²¨ ì»¬ëŸ¼ëª…
        
    Returns:
        (X, y) íŠœí”Œ
    """
    base_path = Path(__file__).parent.parent
    full_path = base_path / data_path
    
    if not full_path.exists():
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_path}")
    
    df = pd.read_csv(full_path)
    df = df.dropna(subset=[text_column, label_column])
    
    X = df[text_column].astype(str)
    y = df[label_column]
    
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(df)}ê°œ")
    return X, y


def train_and_evaluate(
    X_all,
    y_all,
    num_runs: int = 5,
    max_features: int = 5000,
    ngram_range: tuple = (1, 2),
    n_estimators: int = 100,
    max_depth: int = 20,
    min_samples_split: int = 2,
    min_samples_leaf: int = 5,
    n_jobs: int = -1,
    seed: int = 42
):
    """
    ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    
    Args:
        X_all: ì „ì²´ í…ìŠ¤íŠ¸ ë°ì´í„°
        y_all: ì „ì²´ ë¼ë²¨ ë°ì´í„°
        num_runs: ì‹¤í–‰ íšŸìˆ˜
        max_features: TF-IDF ìµœëŒ€ íŠ¹ì„± ìˆ˜
        ngram_range: N-gram ë²”ìœ„
        n_estimators: íŠ¸ë¦¬ ê°œìˆ˜
        max_depth: ìµœëŒ€ ê¹Šì´
        min_samples_split: ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        min_samples_leaf: ë¦¬í”„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        n_jobs: ë³‘ë ¬ ì‘ì—… ìˆ˜
        seed: ì‹œë“œ ê°’
        
    Returns:
        (ëª¨ë¸, ë²¡í„°ë¼ì´ì €, í‰ê°€_ê²°ê³¼) íŠœí”Œ
    """
    val_metrics = {"accuracy": [], "precision": [], "recall": [], "f1": []}
    test_metrics = {"accuracy": [], "precision": [], "recall": [], "f1": []}
    
    last_model = None
    last_vectorizer = None
    
    for run_idx in range(num_runs):
        run_seed = seed + run_idx
        set_seed(run_seed)
        
        # ë°ì´í„° ë¶„í• : 70% train, 30% temp
        X_train, X_temp, y_train, y_temp = train_test_split(
            X_all,
            y_all,
            test_size=0.30,
            random_state=run_seed,
            stratify=y_all
        )
        
        # tempì„ 15% val, 15% testë¡œ ë¶„í• 
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp,
            y_temp,
            test_size=0.50,
            random_state=run_seed,
            stratify=y_temp
        )
        
        print(f"[Run {run_idx+1}] Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
        
        # TF-IDF ë²¡í„°í™”
        vectorizer = TfidfVectorizer(
            max_features=max_features,
            ngram_range=ngram_range,
            min_df=2,
            max_df=0.9
        )
        X_train_tfidf = vectorizer.fit_transform(X_train)
        X_val_tfidf = vectorizer.transform(X_val)
        X_test_tfidf = vectorizer.transform(X_test)
        
        print(f"[Run {run_idx+1}] TF-IDF Train shape: {X_train_tfidf.shape}")
        
        # Random Forest ëª¨ë¸
        rf = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=run_seed,
            n_jobs=n_jobs
        )
        
        # í•™ìŠµ
        print(f"[Run {run_idx+1}] í•™ìŠµ ì¤‘...")
        rf.fit(X_train_tfidf, y_train)
        
        # ê²€ì¦ (Validation)
        y_val_pred = rf.predict(X_val_tfidf)
        print(f"--- [Run {run_idx+1}] Validation Set Results ---")
        print(classification_report(y_val, y_val_pred))
        
        val_accuracy = accuracy_score(y_val, y_val_pred)
        val_precision = precision_score(y_val, y_val_pred, zero_division=0)
        val_recall = recall_score(y_val, y_val_pred, zero_division=0)
        val_f1 = f1_score(y_val, y_val_pred, zero_division=0)
        
        print(f"[Run {run_idx+1}] Val Accuracy: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}")
        
        wandb.log({
            "run_idx": run_idx + 1,
            "val_accuracy": val_accuracy,
            "val_precision": val_precision,
            "val_recall": val_recall,
            "val_f1_score": val_f1
        })
        
        val_metrics["accuracy"].append(val_accuracy)
        val_metrics["precision"].append(val_precision)
        val_metrics["recall"].append(val_recall)
        val_metrics["f1"].append(val_f1)
        
        # ìµœì¢… í‰ê°€ (Test)
        y_test_pred = rf.predict(X_test_tfidf)
        print(f"\n--- [Run {run_idx+1}] Test Set Results (Final) ---")
        print(classification_report(y_test, y_test_pred))
        
        test_accuracy = accuracy_score(y_test, y_test_pred)
        test_precision = precision_score(y_test, y_test_pred, zero_division=0)
        test_recall = recall_score(y_test, y_test_pred, zero_division=0)
        test_f1 = f1_score(y_test, y_test_pred, zero_division=0)
        
        print(f"[Run {run_idx+1}] Test Accuracy: {test_accuracy:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}")
        
        wandb.log({
            "run_idx": run_idx + 1,
            "test_accuracy": test_accuracy,
            "test_precision": test_precision,
            "test_recall": test_recall,
            "test_f1_score": test_f1
        })
        
        test_metrics["accuracy"].append(test_accuracy)
        test_metrics["precision"].append(test_precision)
        test_metrics["recall"].append(test_recall)
        test_metrics["f1"].append(test_f1)
        
        # ë§ˆì§€ë§‰ ëª¨ë¸ê³¼ ë²¡í„°ë¼ì´ì € ì €ì¥
        last_model = rf
        last_vectorizer = vectorizer
    
    # í‰ê·  ê²°ê³¼ ê³„ì‚°
    def _mean(v):
        return float(np.mean(v)) if len(v) > 0 else float("nan")
    
    val_avg = {k: _mean(v) for k, v in val_metrics.items()}
    test_avg = {k: _mean(v) for k, v in test_metrics.items()}
    
    print("\n=== Validation Averages over 5 runs ===")
    print(f"Val Accuracy: {val_avg['accuracy']:.4f}, Val Precision: {val_avg['precision']:.4f}, Val Recall: {val_avg['recall']:.4f}, Val F1: {val_avg['f1']:.4f}")
    
    print("\n=== Test Averages over 5 runs ===")
    print(f"Test Accuracy: {test_avg['accuracy']:.4f}, Test Precision: {test_avg['precision']:.4f}, Test Recall: {test_avg['recall']:.4f}, Test F1: {test_avg['f1']:.4f}")
    
    # wandb summaryì— í‰ê·  ê¸°ë¡
    wandb.summary["val_accuracy_mean"] = val_avg["accuracy"]
    wandb.summary["val_precision_mean"] = val_avg["precision"]
    wandb.summary["val_recall_mean"] = val_avg["recall"]
    wandb.summary["val_f1_mean"] = val_avg["f1"]
    
    wandb.summary["test_accuracy_mean"] = test_avg["accuracy"]
    wandb.summary["test_precision_mean"] = test_avg["precision"]
    wandb.summary["test_recall_mean"] = test_avg["recall"]
    wandb.summary["test_f1_mean"] = test_avg["f1"]
    
    return last_model, last_vectorizer, {"val": val_avg, "test": test_avg}


def save_model(model, vectorizer, model_path: str, vectorizer_path: str = None):
    """
    ëª¨ë¸ ë° ë²¡í„°ë¼ì´ì € ì €ì¥
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        vectorizer: í•™ìŠµëœ ë²¡í„°ë¼ì´ì €
        model_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)
        vectorizer_path: ë²¡í„°ë¼ì´ì € ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ, Noneì´ë©´ ìë™ ìƒì„±)
    """
    base_path = Path(__file__).parent.parent
    model_full_path = base_path / model_path
    model_full_path.parent.mkdir(parents=True, exist_ok=True)
    
    joblib.dump(model, model_full_path)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_full_path}")
    
    if vectorizer_path:
        vectorizer_full_path = base_path / vectorizer_path
        vectorizer_full_path.parent.mkdir(parents=True, exist_ok=True)
        joblib.dump(vectorizer, vectorizer_full_path)
        print(f"ğŸ’¾ ë²¡í„°ë¼ì´ì € ì €ì¥: {vectorizer_full_path}")
    else:
        # ë²¡í„°ë¼ì´ì €ë„ ê°™ì€ ê²½ë¡œì— ì €ì¥ (í™•ì¥ìë§Œ ë‹¤ë¦„)
        vectorizer_path = str(model_path).replace(".pkl", "_vectorizer.pkl")
        vectorizer_full_path = base_path / vectorizer_path
        joblib.dump(vectorizer, vectorizer_full_path)
        print(f"ğŸ’¾ ë²¡í„°ë¼ì´ì € ì €ì¥: {vectorizer_full_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Random Forest ëª¨ë¸ í•™ìŠµ ë° í‰ê°€")
    parser.add_argument("--data", type=str, default="dataset/total_dataset.csv", help="ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)")
    parser.add_argument("--model_path", type=str, default="model/rf_voicephishing.pkl", help="ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ)")
    parser.add_argument("--vectorizer_path", type=str, default=None, help="ë²¡í„°ë¼ì´ì € ì €ì¥ ê²½ë¡œ (ìƒëŒ€ê²½ë¡œ, Noneì´ë©´ ìë™ ìƒì„±)")
    parser.add_argument("--num_runs", type=int, default=5, help="ì‹¤í–‰ íšŸìˆ˜")
    parser.add_argument("--max_features", type=int, default=5000, help="TF-IDF ìµœëŒ€ íŠ¹ì„± ìˆ˜")
    parser.add_argument("--n_estimators", type=int, default=100, help="íŠ¸ë¦¬ ê°œìˆ˜")
    parser.add_argument("--max_depth", type=int, default=20, help="ìµœëŒ€ ê¹Šì´")
    parser.add_argument("--min_samples_split", type=int, default=2, help="ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--min_samples_leaf", type=int, default=5, help="ë¦¬í”„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--n_jobs", type=int, default=-1, help="ë³‘ë ¬ ì‘ì—… ìˆ˜")
    parser.add_argument("--seed", type=int, default=42, help="ì‹œë“œ ê°’")
    parser.add_argument("--wandb_project", type=str, default="Voicephishing", help="WandB í”„ë¡œì íŠ¸ëª…")
    parser.add_argument("--wandb_name", type=str, default=None, help="WandB ì‹¤í–‰ëª… (Noneì´ë©´ ìë™ ìƒì„±)")
    args = parser.parse_args()
    
    wandb.init(project=args.wandb_project, name=args.wandb_name or f"tfidf_rf_{args.num_runs}runs", config={
        "model": "RandomForest", "max_features": args.max_features, "ngram_range": (1, 2), "random_state": args.seed,
        "n_estimators": args.n_estimators, "max_depth": args.max_depth, "min_samples_split": args.min_samples_split,
        "min_samples_leaf": args.min_samples_leaf, "n_jobs": args.n_jobs, "num_runs": args.num_runs,
        "split_ratio": "train 0.70, val 0.15, test 0.15"
    })
    
    try:
        X_all, y_all = load_data(args.data)
        model, vectorizer, metrics = train_and_evaluate(
            X_all=X_all, y_all=y_all, num_runs=args.num_runs, max_features=args.max_features, ngram_range=(1, 2),
            n_estimators=args.n_estimators, max_depth=args.max_depth, min_samples_split=args.min_samples_split,
            min_samples_leaf=args.min_samples_leaf, n_jobs=args.n_jobs, seed=args.seed
        )
        if model is not None:
            save_model(model, vectorizer, args.model_path, args.vectorizer_path)
            try:
                wandb.save(str(Path(__file__).parent.parent / args.model_path))
            except Exception:
                pass
        print("\nâœ… í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        wandb.finish()


if __name__ == "__main__":
    main()

